{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "import requests\n",
    "import pattern3.web as web\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\" This little code extracts all the links in the comments of a webpage.\"\n",
    "\" Written originally for hacker news threads, can be used for similar \"\n",
    "\" websites such as reddit as well\"\n",
    "\" With Pattern \"\n",
    "\n",
    "def get_links(webpage):\n",
    "    \n",
    "    url = webpage\n",
    "    website_html = requests.get(url).text\n",
    "    dom = web.Element(website_html)\n",
    "    \n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    for comment in dom.by_tag(\"div.comment\"):\n",
    "        if comment.by_tag('a') is not None:\n",
    "            links_bycomment = comment.by_tag('a')\n",
    "            for link in links_bycomment:\n",
    "                link_content = link.content \n",
    "                links.append(link_content)\n",
    "                print (link_content)\n",
    "            print (\"\")\n",
    "                \n",
    "    \n",
    "    return list(set(links)) # removes duplicates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\" This little code extracts all the links on the main article of a webpage.\"\n",
    "\" With BeautifulSoup \" \n",
    "    \n",
    "def get_links2(webpage):\n",
    "    \n",
    "    url = web.URL(webpage)\n",
    "    bs = BeautifulSoup(url.download(cached = False)) \n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    for paragraph in bs.findAll('p'):\n",
    "        if paragraph.find('a') is not None:\n",
    "            links_byparagraph = paragraph.findAll('a', href=True)\n",
    "            for link in links_byparagraph:\n",
    "                link_content = link['href']\n",
    "                links.append(link_content)\n",
    "                print (link_content)\n",
    "            print (\"\")\n",
    "                \n",
    "    \n",
    "    return list(set(links)) # removes duplicates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.manning.com/books/taming-text\n",
      "\n",
      "\n",
      "http://garysieling.com/blog/entity-recognition-with-scala-an...\n",
      "http://tika.apache.org\n",
      "http://www.nltk.org\n",
      "http://edeferia.blogspot.com/2015/03/from-natural-language-t...\n",
      "https://www.coursera.org/learn/natural-language-processing\n",
      "\n",
      "https://www.amazon.com/Natural-Language-Processing-Python-An...\n",
      "\n",
      "http://www.nltk.org/book/\n",
      "\n",
      "https://www.youtube.com/watch?v=nfoudtpBV68&list=PL6397E4B26...\n",
      "https://see.stanford.edu/Course/CS229\n",
      "https://www.youtube.com/playlist?list=PLIiVRB6G_w0i-uOoS6cDh...\n",
      "\n",
      "https://web.stanford.edu/~jurafsky/slp3/\n",
      "\n",
      "\n",
      "http://www.nltk.org\n",
      "https://github.com/vseloved/cl-nlp\n",
      "\n",
      "\n",
      "\n",
      "http://hackaday.com/2016/06/08/talking-star-trek/\n",
      "https://scaryreasoner.wordpress.com/2016/05/14/speech-recogn...\n",
      "\n",
      "http://academictorrents.com/details/f99e7184fca947ee8f779016...\n",
      "https://www.youtube.com/playlist?list=PLQVvvaa0QuDf2JswnfiGk...\n",
      "\n",
      "http://nltk.org\n",
      "http://nltk.org/book\n",
      "\n",
      "https://spacy.io/\n",
      "\n",
      "http://explosion.ai\n",
      "\n",
      "https://medium.com/learning-new-stuff/machine-learning-in-a-...\n",
      "\n",
      "https://web.stanford.edu/~jurafsky/slp3/\n",
      "http://nlp.stanford.edu/fsnlp/\n",
      "\n",
      "http://stanfordnlp.github.io/CoreNLP/\n",
      "\n",
      "http://corenlp.run\n",
      "\n",
      "https://github.com/andrewt3000/dl4nlp\n",
      "\n",
      "\n",
      "https://karczmarczuk.users.greyc.fr/TEACH/TAL/Doc/Handbook%2...\n",
      "\n",
      "https://github.com/pickhardt/betty\n",
      "http://iftechfoundation.org/frequently-asked-questions/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://egghead.io/lessons/node-js-break-up-language-strings...\n",
      "\n",
      "https://www.findlectures.com\n",
      "\n",
      "https://github.com/keonkim/awesome-nlp\n",
      "https://lekta.ai/blog/\n",
      "\n",
      "http://mt-class.org/penn/\n",
      "http://www.statmt.org/book/\n",
      "\n",
      "https://www.amazon.com/gp/aw/d/364241463X/ref=dp_ob_neva_mob...\n",
      "\n",
      "https://www.quora.com/How-do-I-learn-Natural-Language-Proces...\n",
      "\n",
      "\n",
      "http://www.mtome.com/Publications/PNLA/prolog-digital.pdf\n",
      "\n",
      "https://sigai.acm.org/index.html\n",
      "\n",
      "http://nlp.stanford.edu/IR-book/\n",
      "\n",
      "\n",
      "http://blog.algorithmia.com/introduction-natural-language-pr...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/odeniz/Downloads/ENTER/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/odeniz/Downloads/ENTER/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\" Ask HN: How Can I Get into NLP (Natural Language Processing)? \"\n",
    "mypage = 'https://news.ycombinator.com/item?id=12916498'\n",
    "mylinks = get_links(mypage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print (len(mylinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sigai.acm.org/index.html',\n",
       " 'http://corenlp.run',\n",
       " 'https://lekta.ai/blog/',\n",
       " 'http://tika.apache.org',\n",
       " 'https://egghead.io/lessons/node-js-break-up-language-strings...',\n",
       " 'https://www.quora.com/How-do-I-learn-Natural-Language-Proces...',\n",
       " 'https://www.youtube.com/watch?v=nfoudtpBV68&list=PL6397E4B26...',\n",
       " 'http://www.mtome.com/Publications/PNLA/prolog-digital.pdf',\n",
       " 'https://www.amazon.com/gp/aw/d/364241463X/ref=dp_ob_neva_mob...',\n",
       " 'http://academictorrents.com/details/f99e7184fca947ee8f779016...',\n",
       " 'http://nlp.stanford.edu/IR-book/',\n",
       " 'http://iftechfoundation.org/frequently-asked-questions/',\n",
       " 'http://nltk.org/book',\n",
       " 'http://mt-class.org/penn/',\n",
       " 'http://nltk.org',\n",
       " 'https://github.com/pickhardt/betty',\n",
       " 'http://nlp.stanford.edu/fsnlp/',\n",
       " 'https://web.stanford.edu/~jurafsky/slp3/',\n",
       " 'https://github.com/keonkim/awesome-nlp',\n",
       " 'http://edeferia.blogspot.com/2015/03/from-natural-language-t...',\n",
       " 'http://stanfordnlp.github.io/CoreNLP/',\n",
       " 'https://see.stanford.edu/Course/CS229',\n",
       " 'https://medium.com/learning-new-stuff/machine-learning-in-a-...',\n",
       " 'https://github.com/vseloved/cl-nlp',\n",
       " 'https://scaryreasoner.wordpress.com/2016/05/14/speech-recogn...',\n",
       " 'https://www.coursera.org/learn/natural-language-processing',\n",
       " 'https://www.amazon.com/Natural-Language-Processing-Python-An...',\n",
       " 'http://explosion.ai',\n",
       " 'http://blog.algorithmia.com/introduction-natural-language-pr...',\n",
       " 'https://www.manning.com/books/taming-text',\n",
       " 'http://garysieling.com/blog/entity-recognition-with-scala-an...',\n",
       " 'https://www.youtube.com/playlist?list=PLIiVRB6G_w0i-uOoS6cDh...',\n",
       " 'https://karczmarczuk.users.greyc.fr/TEACH/TAL/Doc/Handbook%2...',\n",
       " 'http://www.nltk.org',\n",
       " 'http://hackaday.com/2016/06/08/talking-star-trek/',\n",
       " 'http://www.nltk.org/book/',\n",
       " 'https://www.findlectures.com',\n",
       " 'http://www.statmt.org/book/',\n",
       " 'https://spacy.io/',\n",
       " 'https://github.com/andrewt3000/dl4nlp',\n",
       " 'https://www.youtube.com/playlist?list=PLQVvvaa0QuDf2JswnfiGk...']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import simplejson\n",
    "f = open('output.txt', 'w')\n",
    "simplejson.dump(mylinks, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><Br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://en.wikipedia.org/wiki/Bag-of-words_model\n",
      "\n",
      "http://www.kaggle.com/c/titanic-gettingStarted\n",
      "\n",
      "http://www.nltk.org/book/\n",
      "\n",
      "https://github.com/wendykan/DeepLearningMovies/blob/master/BagOfWords.py\n",
      "\n",
      "http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "\n",
      "https://docs.python.org/2/library/re.html#\n",
      "\n",
      "http://en.wikipedia.org/wiki/Tokenization\n",
      "\n",
      "http://en.wikipedia.org/wiki/Stop_words\n",
      "http://www.nltk.org\n",
      "http://www.nltk.org/install.html\n",
      "\n",
      "https://docs.python.org/2/howto/unicode.html#python-2-x-s-unicode-support\n",
      "\n",
      "http://en.wikipedia.org/wiki/Bag-of-words_model\n",
      "\n",
      "http://scikit-learn.org/stable/install.html\n",
      "\n",
      "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
      "\n",
      "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
      "\n",
      "http://blog.kaggle.com/2012/07/06/the-dangers-of-overfitting-psychopathy-post-mortem/\n",
      "\n",
      "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/odeniz/Downloads/ENTER/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/odeniz/Downloads/ENTER/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://www.kaggle.com/c/titanic-gettingStarted',\n",
       " 'http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs4/doc/',\n",
       " 'http://en.wikipedia.org/wiki/Stop_words',\n",
       " 'http://www.nltk.org/install.html',\n",
       " 'https://docs.python.org/2/howto/unicode.html#python-2-x-s-unicode-support',\n",
       " 'http://scikit-learn.org/stable/install.html',\n",
       " 'http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html',\n",
       " 'https://docs.python.org/2/library/re.html#',\n",
       " 'http://en.wikipedia.org/wiki/Bag-of-words_model',\n",
       " 'http://en.wikipedia.org/wiki/Tokenization',\n",
       " 'http://www.nltk.org',\n",
       " 'https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews',\n",
       " 'http://www.nltk.org/book/',\n",
       " 'https://github.com/wendykan/DeepLearningMovies/blob/master/BagOfWords.py',\n",
       " 'http://blog.kaggle.com/2012/07/06/the-dangers-of-overfitting-psychopathy-post-mortem/']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylink3 = 'https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words'\n",
    "get_links2(mylink3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
